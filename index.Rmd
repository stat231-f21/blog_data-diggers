---
title: | 
  [![kickstarter](kickstarter.jpg){width=2in}](https://www.kickstarter.com/?ref=nav)
subtitle: "Analyzing and Modeling Kickstarter Data: What are the drivers of success for Kickstarter campaigns?"
author: "Dan and Karla"
date: "November 30, 2021"
output:
  rmdformats::robobook:
    thumbnails: false
    highlight: "kate"
---

```{r setup, include = FALSE}
library(tidyverse)
library(kableExtra) # for example code; delete if not needed
library(tidytext)
library(tidyverse)
library(ggplot2)
library(lubridate)
library(plotly)
library(gganimate)
library(gifski)
library(cowplot)
library(Stat2Data) # for emplogitplot1()
library(ggformula) # for gf_percents()
library(lmtest) # lrt test
library(gt) # to create a pretty conf matrix
library(MLmetrics) # for precision/recall

# Set code chunk defaults 
knitr::opts_chunk$set(echo = FALSE, 
                      mesage = FALSE,
                      warning = FALSE,
                      fig.align = "center")
# set reproducible randomness
set.seed(123)
# Set R environment options
options(knitr.kable.NA = '')
```

# Introduction

Kickstarter, founded in 2009, is an online crowdfunding platform. Their mission is to help "bring creative projects to life" (Kickstarter, 2009) as individuals can create projects that draw others to support the process. 

Source: Kickstarter. (2009, April). _About_ https://www.kickstarter.com/about


# Success by State and Category

<!--- iframe allows for more customization than include_app(), doesn't cut off edges -->
<iframe src="https://ddachille23.shinyapps.io/MapGadgetApp/" height="600" width="720" style="border: 1px solid #464646;" data-external="1"></iframe>


# Text Analysis 

## Text Length and Outcome {.tabset .tabset-fade .tabset-pills}

```{r echo = FALSE}
# read in data
kickstarter <- read.csv("kickstarter_2020.csv")
# wrangle
text <- kickstarter %>%
  select(blurb, name, outcome, main_category)

small_data <- kickstarter %>%
  select(blurb, name)

# remove stop words 
data(stop_words)
wordcloud_data <- text %>%
   unnest_tokens(output = word, input = blurb) %>%
   anti_join(stop_words, by = "word")

# join text
new_text <- inner_join(wordcloud_data, small_data, by = "name")
```

### Name Length

```{r echo = FALSE}
# blurb length by outcome
length_data <- text %>% 
  mutate (blurb_length = nchar(blurb),
          name_length = nchar(name))
length_summary <- length_data %>% 
  group_by(outcome) %>% 
  summarise(mean_blurb_length = mean(blurb_length), n = n(),
            mean_name_length = round(mean(name_length), 1)) %>% 
  mutate(mean_blurb_length = round(mean_blurb_length, 1),
         outcome = as.factor(outcome))
# reorder levels of outcome factor
length_summary$outcome <- factor(length_summary$outcome, levels=rev(levels(length_summary$outcome)))

# name length plot
ggplot(length_summary, aes(x = mean_name_length, y = outcome)) + 
  geom_bar(stat = "identity", aes(fill = outcome)) +
  theme_minimal() + labs(x = "Mean Name Length (characters)", y = "Outcome", title = "Name Length by Outcome") + 
  geom_label(aes(label = mean_name_length)) +
  scale_fill_manual(values=c("#05ce78", "#ed4752")) +
  theme(legend.position = "none")
```


### Blurb Length

```{r echo = FALSE}
# blurb length plot
ggplot(length_summary, aes(x = mean_blurb_length, y = outcome)) + 
  geom_bar(stat = "identity", aes(fill = outcome)) +
  theme_minimal() + labs(x = "Mean Blurb Length (characters)", y = "Outcome", title = "Blurb Length by Outcome") + 
  geom_label(aes(label = mean_blurb_length)) +
  scale_fill_manual(values=c("#05ce78", "#ed4752")) +
  theme(legend.position = "none")

```


## Sentiment Analysis {.tabset .tabset-fade .tabset-pills}

### Bing Lexicon

```{r echo = FALSE, message = FALSE}
# using bing lexicon (pos or neg)
bing <- get_sentiments("bing")

# join in bing and get blurb length
blurb_sentiment <- new_text %>% 
  inner_join(bing) 

# creating sentiment score
tt_bing <- blurb_sentiment %>% 
  group_by(name, outcome) %>% 
  summarize(sentiment_score = sum(sentiment == "positive") - sum(sentiment == "negative"),
            tPos = sum(sentiment == "positive"), tNeg = sum(sentiment == "negative"))
# make table
bing_tbl <- tt_bing %>% 
  group_by(outcome) %>% 
  summarise(mean_sent_score = mean(sentiment_score),
            sd = sd(sentiment_score),
            median = median(sentiment_score))
bing_tbl_pretty <- bing_tbl %>% 
  mutate(mean_sent_score = round(mean_sent_score, 3)) %>% 
  select(outcome, mean_sent_score) %>% 
  rename(Outcome = outcome, 
         "Mean Sentiment Score" = mean_sent_score) %>% 
  kbl() %>%
  kable_material("hover")

# sentiment score faceted plot
ggplot(data = tt_bing, aes(x = sentiment_score, fill = outcome)) + 
  geom_histogram(bins = 15) +
  facet_grid(~outcome) + 
  labs(title = "Blurb Sentiment Score by Outcome", x = "Sentiment Score (Bing lexicon)") + 
  scale_fill_manual(values = c("#ed4752", "#05ce78")) +
  theme_bw() +
  theme(legend.position = "none") 
bing_tbl_pretty
```

### Afinn Lexicon

```{r echo = FALSE, message = FALSE}
# using afinn lexicon
afinn <- get_sentiments("afinn")

blurb_sentiment_fin <- new_text %>% 
  inner_join(afinn)

# get sentiment score
tt_afinn <- blurb_sentiment_fin %>% 
  group_by(name, outcome) %>% 
  summarize(sentiment_score = sum(value))

# make table
afinn_tbl <- tt_afinn %>% 
  group_by(outcome) %>% 
  summarise(mean_sent_score = mean(sentiment_score),
            sd = sd(sentiment_score),
            median = median(sentiment_score)) 
afinn_tbl_pretty <- afinn_tbl %>% 
  mutate(mean_sent_score = round(mean_sent_score, 3)) %>% 
  select(outcome, mean_sent_score) %>% 
  rename(Outcome = outcome, 
         "Mean Sentiment Score" = mean_sent_score) %>% 
  kbl() %>%
  kable_material("hover")


# sentiment score faceted plot
ggplot(data = tt_afinn, aes(x = sentiment_score, fill = outcome)) + 
  geom_histogram(bins = 15) +
  facet_grid(~outcome) + 
  labs(title = "Blurb Sentiment Score by Outcome", x = "Sentiment Score (Afinn lexicon)") + 
  scale_fill_manual(values = c("#ed4752", "#05ce78")) +
  theme_bw() +
  theme(legend.position = "none") 
afinn_tbl_pretty
```


## Word Cloud

<iframe src="https://ddachille23.shinyapps.io/WordCloudApp/" height="780" width="720" style="border: 1px solid #464646;" data-external="1"></iframe>


# Project Launch Analysis

This section focuses on the launching process of a Kickstarter project. We aim to examine the trends of successful projects through 2009-2020 based on launch month, launch day, success rates throughout the years, and campaign length. 

## Launch Month and Success Rate

#### What is the best month to launch a project?

```{r}
# wrangling
date_data <- kickstarter %>%
  select(c("launched_at", "outcome", "proportion_funded", "pct_funded", "campaign_length")) %>%
  separate(launched_at, c("date", "time"), sep = " ") %>%
  mutate(month = months(as.Date(date)),
         day = weekdays(as.Date(date)),
         year = year(as.Date(date))) 
# dataset for month
month_data <- date_data %>%
  group_by(month) %>%
  summarise(n = n(),
            success_rate = sum(outcome=="successful")/n)
# creating bar plot
p2 <- month_data %>%
  ggplot(aes(x = month, y = success_rate)) +
  geom_bar(stat = "identity", fill = "#05ce78") + coord_flip() +
  labs(title = "Success Rate by Launch Month", 
       x = "Month",
       y = "Success Rate") +
  scale_x_discrete(limits = rev(c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"))) +
  geom_label(aes(label = round(success_rate, 3))) +
  theme_minimal()
p2
```


## Launch Day and Success Rate

#### What is the best day to launch a project?

```{r}
#dataset for day
day_data <- date_data %>%
  group_by(day) %>%
  summarise(n = n(),
            success_rate = sum(outcome=="successful")/n) 
# day barplot
ggplot(data = day_data, aes(x = day, y = success_rate)) +
  geom_bar(stat = "identity", fill = "#05ce78") +
  labs(title = "Success Rate by Launch Day",
       x = "Day",
       y = "Success Rate") +
  scale_x_discrete(limits = c("Sunday", "Monday", "Tuesday", "Wednesday",
                              "Thursday", "Friday", "Saturday")) +
  geom_label(aes(label = round(success_rate, 3))) +
  theme_minimal()
```

## Trend in Success Rate 2009-2020

```{r}
# dataset for year
year_data <- date_data %>%
  group_by(year) %>%
  summarise(n = n(),
            success_rate = sum(outcome=="successful")/n) 

# creating line plot for year 
gif_plot_year <- ggplot(year_data, aes(x = year, y = success_rate)) +
  geom_line(color = "#05ce78") + geom_point() +
  labs(title = "Trend in Outcome of Kickstarter Projects by Year",
       x = "Year",
       y = "Success Rate") +
  transition_reveal(year) +
  theme_minimal() + 
  geom_text(aes(label = scales::percent(success_rate, accuracy = 1),
                vjust = -2), show.legend = FALSE)

# saving line plot into a gif
animate(gif_plot_year, duration = 6, fps = 40, width = 450, height = 400, renderer = gifski_renderer())
#anim_save("line-plot.gif")

```


## Campaign Length and Success Rate {.tabset .tabset-fade .tabset-pills}

From 2009-2011, Kickstarter creators were able to set campaign lengths of up to 90 days. However, in 2011, Kickstarter claimed that through their own research, they found that projects lasting longer than 60 days were less successful than projects with shorter campaign lengths, Thus, after 2011, campaign lengths were recommended to be at most 30-60 days (Strickler, 2011). 

In this section, we analyze the validity of Kickstarter's findings: Do shorter campaign lengths correlate with higher success rates on Kickstarter projects? 

### 2011

```{r, message = FALSE}
# dataset for campaign length (2011)
camplength1 <- date_data %>%
  group_by(campaign_length, year) %>%
  filter(year == 2011) %>%
  summarise(n = n(),
            success_rate = sum(outcome=="successful")/n) 

# plot for campaign length 2011
ggplot(camplength1, aes(x = campaign_length, y = success_rate, size = n)) +
  geom_smooth(method = "glm", color = "#05ce78") + geom_point() +
  labs(title = "Success of Kickstarter Projects by Campaign Length (2011)",
       x = "Campaign Length (in days)",
       y = "Success Rate",
       size = "Number of Campaigns") +
  theme_minimal()
```

### 2012-2020

```{r, message = FALSE}
# for 2012-2020
camplength2 <- date_data %>%
  group_by(campaign_length, year) %>%
  filter(year > 2011, campaign_length <= 60) %>%
  summarise(n = n(),
            success_rate = sum(outcome=="successful")/n) 

# plot for campaign length 2012-2020
ggplot(camplength2, aes(x = campaign_length, y = success_rate, size = n)) +
  geom_smooth(method = "glm", color = "#05ce78") + geom_point() +
  labs(title = "Success of Kickstarter Projects by Campaign Length (2011-2020)",
       x = "Campaign Length (in days)",
       y = "Success Rate",
       size = "Number of Campaigns") +
  facet_wrap(~ year) +   
  scale_size_continuous(limits = c(1, 10000)) +
  theme_minimal()
```


# Logistic Regression Model to Predict Success Rate
```{r prepare data}
# cast categorical predictors into factors, mutate outcome into 0 = failed, 1 = successful
kickstarter_init <- kickstarter %>% 
  mutate(outcome = ifelse(outcome == "successful", 1, 0),
         main_category = as.factor(main_category),
         sub_category = as.factor(sub_category),
         city = as.factor(city),
         state = as.factor(state),
         country_corrected = as.factor(country_corrected),
         launched_at = date(launched_at))

# subset data to relevant variables
kickstarter_subset <- kickstarter_init %>% 
  select(backers_count, country_display_name_corrected, launched_at, spotlight, staff_pick, outcome, goal_usd, pledged_usd, campaign_length, main_category, sub_category, city, state, proportion_funded, name, blurb) %>% 
  mutate(launch_month = month(launched_at),
         launch_day = wday(launched_at),
         name_length = str_length(name),
         blurb_length = str_length(blurb))
```

## Train-Test Split
```{r 70-30 data split, echo = TRUE}
sample <- sample(c(TRUE, FALSE), nrow(kickstarter_subset), 
                 replace = TRUE, prob = c(0.7,0.3))
train <- kickstarter_subset[sample, ]
test <- kickstarter_subset[!sample, ]
```

## Predictors
1) `goal_usd` (Quantitative, $): The chosen amount of money in USD a company needs to raise to have a successful campaign.
2) `campaign_length` (Quantitative, Days): The chosen length of the campaign, ranging from 0-90 in 2009-2011, and 0-60 in 2012-2020.
3) `name_length` (Quantitative, Characters): The length of the startup's name.
4) `staff_pick` (Categorical, TRUE/FALSE): Whether or not the project was selected by the staff at Kickstarter to be included in the "Projects we Love" section.
5) `main_category` (Categorical): The main category of the campaign. There are 14 main categories (Art, Comics, Crafts, ... etc.).
6) `launch_day` (Categorical): The day of the week in which the campaign was launched.
7) `launch_month` (Categorical): The month in which the campaign was launched.

## Conditions for Logistic Regression 
- Is `outcome` binary? Yes `outcome` is binary (success/fail).
- Linearity: Checked for quantitative predictors below, automatic for categorical predictors.
- Independence of observations:  It is reasonable to assume that Kickstarter campaigns independent. 
- Randomness: We know that we didn't capture all Kickstarter campaigns from 2009-2020, but we will assume that the 170,000 scraped campaigns are a random subset of the population.

## EDA

### Response Variable - Kickstarter Campaign Outcome
```{r}
outcome_summary_tbl <- train %>% group_by(outcome) %>% summarise(n = n()) %>% 
  mutate(freq = round(n/sum(n), 4),
         outcome = ifelse(outcome == 1, "Successful", "Failed")) %>% 
  rename("Outcome" = outcome, "Number of Campaigns" = n, "Frequency of Campaigns" = freq)
outcome_summary_tbl%>%  
  kbl() %>%
  kable_material("hover")
```

56.9% of all Kickstarter campaigns in the training set were successful.

### Quantitative Predictors - Check Linearity of Predictors and log-odds {.tabset .tabset-fade .tabset-pills}

#### Goal
```{r}
# QUANT PREDICTOR 1 - GOAL
emplogitplot1(outcome ~ goal_usd, data = train, ngroups = 15, xlab = "goal ($)", main = "Goal Empirical Logit Plot")
```

#### Sqrt(Goal)
```{r}
# SQRT GOAL
# transform variable - for BOTH training and testing set
train <- train %>% mutate(sqrt_goal_usd = sqrt(goal_usd))
test <- test %>% mutate(sqrt_goal_usd = sqrt(goal_usd))

emplogitplot1(outcome ~ sqrt_goal_usd, data = train, ngroups = 15, xlab = "sqrt(goal)", main = "Square Root Transformed Goal Empirical Logit Plot")
```

#### Name Length
```{r}
# QUANT PREDICTOR 2 - NAME LENGTH
emplogitplot1(outcome ~ name_length, data = train, ngroups = 15, xlab = "name length (characters)", main = "Name Length Empirical Logit Plot")
```

#### Campaign Length
```{r}
# QUANT PREDICTOR 3 - CAMPAIGN LENGTH
emplogitplot1(outcome ~ campaign_length, data = train, xlab = "campaign length (days)", ngroups = "all", main = "Campaign Length Emprical Logit Plot")
```

### {-}

`goal_usd` does not initially have a linear relationship with the log odds of the outcome, so we applied a square root transformation. A square root transformation will inflate smaller goals and stabilize larger ones, which is helpful here because of the right skewed distribution of Kickstarter goals. `name_length` has a linear relationship with the log odds of the outcome. 
The empirical logit plot for `campaign_length` looks concerning. 

### Categorical Variables  {.tabset .tabset-fade .tabset-pills}

#### Staff Pick
```{r}
# staff pick
gf_percents(~ staff_pick, fill = ~ as.factor(outcome), position = "fill", data = train, title = "Staff Pick Mosiac Plot", xlab = "Staff Pick", ylab = "Outcome Percent") +
  scale_fill_manual(name = "Outcome", labels = c("0 - Failed", "1 - Succcessful"), values = c("#ed4752", "#05ce78"))
```

```{r eval = FALSE}
# raw numbers
train %>% group_by(staff_pick) %>% summarize(freq = sum(outcome == 1)/n())
```


#### Launch Category
```{r}
# main category
gf_percents(~ main_category, fill = ~ as.factor(outcome), position = "fill", data = train, title = "Main Category Mosiac Plot", xlab = "Main Category", ylab = "Outcome Percent") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_fill_manual(name = "Outcome", labels = c("0 - Failed", "1 - Succcessful"), values = c("#ed4752", "#05ce78"))
```

```{r eval = FALSE}
# raw numbers
train %>% group_by(main_category) %>% summarize(freq = sum(outcome == 1)/n()) %>% arrange(desc(freq))
```

#### Launch Weekday
```{r}
# launch day of week 
train_g <- train %>% 
  mutate(launch_day = as.character(launch_day),
         launch_day = case_when(launch_day == "1" ~ "Sunday",
                                 launch_day == "2" ~ "Monday",
                                 launch_day == "3" ~ "Tuesday",
                                 launch_day == "4" ~ "Wednesday",
                                 launch_day == "5" ~ "Thursday",
                                 launch_day == "6" ~ "Friday",
                                 launch_day == "7" ~ "Saturday",
                            TRUE ~ launch_day),
                            launch_day = as.factor(launch_day)) 
train_g$launch_day <- factor(train_g$launch_day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
                          
gf_percents(~ factor(launch_day), fill = ~ as.factor(outcome), position = "fill", data = train_g, title = "Launch Weekday Mosiac Plot", xlab = "Launch Weekday", ylab = "Outcome Percent") + 
  scale_fill_manual(name = "Outcome", labels = c("0 - Failed", "1 - Succcessful"), values = c("#ed4752", "#05ce78")) 
```

```{r eval = FALSE}
# raw numbers
train_g %>% group_by(launch_day) %>% summarize(freq = sum(outcome == 1)/n())
```

#### Launch Month
```{r}
# launch month
gf_percents(~ factor(launch_month), fill = ~ as.factor(outcome), position = "fill", data = train, title = "Launch Month Mosiac Plot", xlab = "Launch Month", ylab = "Outcome Percent") + 
  scale_fill_manual(name = "Outcome", labels = c("0 - Failed", "1 - Succcessful"), values = c("#ed4752", "#05ce78"))
```

```{r eval = FALSE}
# raw numbers
train_g %>% group_by(launch_month) %>% summarize(freq = sum(outcome == 1)/n()) %>% arrange(desc(freq))
```

### {-}

- `staff_pick`: 51.9% of campaigns that were not staff picks were successful, while 90.1% of campaigns that were staff picks were successful.
- `main_category`: The top 3 categories were comics, publishing, and games: 87.8% of comic campaigns were successful, 70.2% of publishing campaigns were successful, and 69.4% of game campaigns were successful. The bottom 3 categories were Journalism, Crafts, and Food: 23.1% of journalism campaigns were successful, 28.5% of craft campaigns were successful, and 29.4% of food campaigns were successful.
- `launch_day`: Tuesday is the best day to launch a campaign, as 60.7% of campaigns launched on Tuesday were successful. Saturday is the worst, since only 54.3% of campaigns launched on that day were successful.
- `launch_month`: October is the best month to launch a campaign, as 59.7% of campaigns launched in October were successful. December is the worst, since only 50.6% of campaigns launched in December were successful.


## Model Fitting

```{r model fit, echo = TRUE}
mod.full <- glm(outcome ~ sqrt_goal_usd + name_length + campaign_length + 
                  staff_pick + launch_day + launch_month + 
                  main_category, data = train, family = "binomial")
mod.small <- glm(outcome ~ sqrt_goal_usd + name_length + 
                   campaign_length + staff_pick + launch_day + 
                   launch_month, data = train, family = "binomial")
mod.final <- glm(outcome ~ sqrt_goal_usd + name_length + 
                   campaign_length + staff_pick + launch_day + 
                   main_category, data = train, family = "binomial")
```

```{r model summary, eval = FALSE}
summary(mod.full)
summary(mod.small)
summary(mod.final)
```

Using a Wald test for each predictor, all predictors are significant at an alpha level of 0.05, with the exception of launch_month and a single level of the `main_category` predictor. We will remove launch_month since it is not significant. There does not appear to be a significant difference between the dance category and our baseline category, art. In order to see if we should keep the predictor `main_category` in our model, we will perform a nested likelihood ratio test (LRT).

```{r}
lrtest(mod.full, mod.small)
```

The nested LRT returns a significant p-value, meaning that the additional predictor, `main_cateogry`, significantly helps in the prediction of the log(odds) of the outcome. Therefore, we will keep `main_category` in the final model. The final model has the lowest AIC, so we will proceed with that model.

## Final Model Interpretation

The predictor with the largest effect size is `staff_pick`. The indicator variable `staff_pickTRUE` has a coefficient of 2.61 with an extremely small p-value. An intercept of 2.61 means that the estimated odds of success for a campaign that is a staff pick is 13.6 times higher than a campaign that is not a staff pick, after accounting for the effect of the other predictors (since $e^\hat\beta = odds\space ratio$). The predictor with the next largest effect size is `main_categoryComics`, with a coefficient of 1.49 and an extremely small p-value. An intercept of 1.49 means that the estimated odds of success for a comic book campaign is 4.44 times higher than a campaign with the baseline category, art, after accounting for the effect of the other predictors.  

## Model Evaluation

```{r}
# get predicted values
test.predicted.mod.final <-  predict(mod.final, newdata = test, type = "response")
#table(test$outcome, test.predicted.mod.final > 0.5) %>% prop.table() %>% round(3)
conf.matrix <- table(test$outcome, test.predicted.mod.final > 0.5)

# make pretty confusion matrix
pretty.conf.matrix <- as.data.frame(conf.matrix) %>% 
  pivot_wider(names_from = Var2, values_from = Freq) %>% 
  mutate(Var1 = as.character(Var1),
         Var1 = ifelse(Var1 == "0", "True Failure", "True Success")) %>% 
  gt() %>% 
  cols_label(Var1 = " ", `FALSE` = "Predicted Failure", `TRUE` =  "Predicted Success") %>% 
  tab_header(title = md("Confusion Matrix")) %>% 
  tab_options(heading.title.font.size = 18) %>% 
  tab_style(
    style = list(
      cell_fill(color = "#05ce78"),
      cell_text(style = "italic")
      ),
    locations = cells_body(
      columns = `FALSE`,
      rows = 1
    )
  ) %>% 
  tab_style(
    style = list(
      cell_fill(color = "#05ce78"),
      cell_text(style = "italic")
      ),
    locations = cells_body(
      columns = `TRUE`,
      rows = 2
    )
  ) %>% 
  tab_style(
    style = list(
      cell_fill(color = "#ed4752",
                 alpha = 0.9)
      ),
    locations = cells_body(
      columns = `FALSE`,
      rows = 2
    )
  ) %>% 
  tab_style(
    style = list(
      cell_fill(color = "#ed4752",
                alpha = 0.9)
      ),
    locations = cells_body(
      columns = `TRUE`,
      rows = 1
    )
  )
pretty.conf.matrix
```

```{r eval = FALSE}
Accuracy(ifelse(test.predicted.mod.final >= .5, 1, 0), test$outcome)
Precision(test$outcome, ifelse(test.predicted.mod.final >= .5, 1, 0), positive = 1) # true pos rate
Recall(test$outcome, ifelse(test.predicted.mod.final >= .5, 1, 0), positive = 1) # sensitivity
```

$$Accuracy =  \frac{(TP + TN)}{(TP + TN + FP + FN)} = \frac{(24055 + 12808)}{(24055 + 12808 + 9477 + 4958)} = 0.7186$$

The model is 71.86% accurate, meaning that it predicts the correct outcome 71.86% of the time.

$$Precision =  \frac{(TP)}{(TP + FP)} = \frac{(24055)}{(24055 + 9477)} = 0.7174$$


The model's precision is 71.74%, meaning that 71.74% of the campaigns predicted to be successful were truly successful. In other words, when it predicts a campaign will be successful, it is correct 71.74% of the time.

$$Recall =  \frac{(TP)}{(TP + FN)} = \frac{(24055)}{(24055 + 4958)} = 0.8291$$


The model's recall is 82.91%, meaning that of all the successful campaigns, the model correctly predicted them to be successful 82.91% of the time (true positive rate). In other words, it correctly identifies 82.91% of all successful campaigns. 

# Prediction App

<iframe src="https://ddachille23.shinyapps.io/LogitModelApp/" height="650" width="720" style="border: 1px solid #464646;" data-external="1"></iframe>




